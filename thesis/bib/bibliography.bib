@book{kress89,
    title = {Linear Integral Equations},
    author = {Rainer Kress},
    series = {Applied Mathematical Sciences},
    year = {1989},
    publisher = {Springer-Verlag},
}

@book{wooldridge2001,
    title = {Econometric Analysis of Cross Section and Panel Data},
    author = {Jeffrey M. Wooldridge},
    isbn = {9780262232197},
    year = {2001},
    publisher = {The MIT Press},
}

@book{hernan2020,
    title = {Causal Inference: What If},
    author = {Miguel A. Hernán and James M. Robins},
    year = {2020},
    publisher = {Chapman \& Hall/CRC},
}

@book{lehmann59,
    title = {Testing Statistical Hypotheses},
    author = {E. L. Lehmann},
    year = {1959},
    publisher = {John Wiley \& Sons},
}

@book{munkres2000,
    title = {Topology},
    author = {James R. Munkres},
    year = {2000},
    publisher = {Prentice Hall, Inc},
}

@book{rudin1991,
    title = {Functional Analysis},
    author = {Walter Rudin},
    year = {1991},
    publisher = {McGraw-Hill},
}

@book{pathak2018,
    title = {An Introduction to Nonlinear Analysis and Fixed Point Theory},
    author = {Hemant Kumar Pathak},
    year = {2018},
    publisher = {Springer},
}

@book{hsing2015,
    title = {Theoretical Foundations of Functional Data Analysis, with and Introduction to Linear Operators},
    author = {Tailen Hsing and Randall Eubank},
    series = {Wiley Series in Probability and Statistics},
    year = {2015},
    publisher = {John Wiley \& Sons},
}

@book{sugiyama2012,
    title = {Density Ration Estimation in Machine Learning},
    author = {Masashi Sugiyama, Taiji Suzuki, Takafumi Kanamori},
    year = {2012},
    publisher = {Cambridge University Press},
}

@book{svm2008,
    title = {Support Vector Machines},
    author = {Ingo Steinart and Andreas Christmann},
    series = {Information Science and Statistics},
    year = {2008},
    publisher = {Springer},
}

@inbook{florens2007,
  author    = {Marine Carrasco and Jean-Pierre Florens and Eric Renault},
  title     = {Handbook of Econometrics},
  chapter   = {Linear Inverse Problems in Structural Econometrics Estimation Based on Spectral Decomposition and Regularization},
  publisher = {Elsevier},
  year      = {2007},
  volume    = {6B},
}

@article{nadaraya64,
    author = {E. A. Nadaraya},
    title = {On Estimating Regression},
    journal = {Theory of Probability \& its Applications},
    volume = {9},
    number = {1},
    pages = {141-142},
    year = {1964},
}

@article{watson64,
    author = {Geoffrey S. Watson},
    title = {Smooth Regression Analysis},
    journal = {Sankhyā: The Indian Journal of Statistics, Series A},
    volume = {26},
    number = {4},
    pages = {359-372},
    year = {1964},
}

@article{newey2003,
    title={Instrumental Variable Estimation of Nonparametric Models},
    author={Whitney K. Newey and James L. Powell},
    year={2003},
    journal={Econometrica},
    volume = {71},
    number = {5},
    pages = {1565-1578},
    DOI = {http://dx.doi.org/10.1111/1468-0262.00459},
}

@article{darolles2011,
    author = {S. Darolles and Y. Fan and J. P. Florens and E. Renault},
    title = {Nonparametric Instrumental Regression},
    journal = {Econometrica},
    volume = {79},
    number = {5},
    pages = {1541--5165},
    year = {2011}
}

@article{deepgmm2019,
    author = {Andrew Bennet and Nathan Kallus and Tobias Schnabel},
    title = {Deep Generalized Method of Moments for Instrumental Variable Analysis},
    journal = {NeurIPS},
    year = {2019},
}

@InProceedings{representer2001,
    author="Sch{\"o}lkopf, Bernhard
    and Herbrich, Ralf
    and Smola, Alex J.",
    editor="Helmbold, David
    and Williamson, Bob",
    title="A Generalized Representer Theorem",
    booktitle="Computational Learning Theory",
    year="2001",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="416--426",
    isbn="978-3-540-44581-4"
}


@inproceedings{singh2019,
    author = {Singh, Rahul and Sahani, Maneesh and Gretton, Arthur},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Kernel Instrumental Variable Regression},
    url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/17b3c7061788dbe82de5abe9f6fe22b3-Paper.pdf},
    volume = {32},
    year = {2019}
}

@inproceedings{cme2009, author = {Song, Le and Huang, Jonathan and Smola, Alex and Fukumizu, Kenji}, title = {Hilbert Space Embeddings of Conditional Distributions with Applications to Dynamical Systems}, year = {2009}, isbn = {9781605585161}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1553374.1553497}, doi = {10.1145/1553374.1553497}, abstract = {In this paper, we extend the Hilbert space embedding approach to handle conditional distributions. We derive a kernel estimate for the conditional embedding, and show its connection to ordinary embeddings. Conditional embeddings largely extend our ability to manipulate distributions in Hilbert spaces, and as an example, we derive a nonparametric method for modeling dynamical systems where the belief state of the system is maintained as a conditional embedding. Our method is very general in terms of both the domains and the types of distributions that it can handle, and we demonstrate the effectiveness of our method in various dynamical systems. We expect that conditional embeddings will have wider applications beyond modeling dynamical systems.}, booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning}, pages = {961–968}, numpages = {8}, location = {Montreal, Quebec, Canada}, series = {ICML '09} }

@inproceedings{deepiv2017, author = {Hartford, Jason and Lewis, Greg and Leyton-Brown, Kevin and Taddy, Matt}, title = {Deep IV: A Flexible Approach for Counterfactual Prediction}, year = {2017}, publisher = {JMLR.org}, abstract = {Counterfactual prediction requires understanding causal relationships between so-called treatment and outcome variables. This paper provides a recipe for augmenting deep learning methods to accurately characterize such relationships in the presence of instrument variables (IVs)—sources of treatment randomization that are conditionally independent from the outcomes. Our IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework allows us to take advantage of off-the-shelf supervised learning techniques to estimate causal effects by adapting the loss function. Experiments show that it outperforms existing machine learning approaches.}, booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70}, pages = {1414–1423}, numpages = {10}, location = {Sydney, NSW, Australia}, series = {ICML'17} }

@inproceedings{dualiv2020, author = {Muandet, Krikamol and Mehrjou, Arash and Lee, Si Kai and Raj, Anant}, title = {Dual Instrumental Variable Regression}, year = {2020}, isbn = {9781713829546}, publisher = {Curran Associates Inc.}, address = {Red Hook, NY, USA}, abstract = {We present a novel algorithm for non-linear instrumental variable (IV) regression, DualIV, which simplifies traditional two-stage methods via a dual formulation. Inspired by problems in stochastic programming, we show that two-stage procedures for non-linear IV regression can be reformulated as a convex-concave saddle-point problem. Our formulation enables us to circumvent the first-stage regression which is a potential bottleneck in real-world applications. We develop a simple kernel-based algorithm with an analytic solution based on this formulation. Empirical results show that we are competitive to existing, more complicated algorithms for non-linear instrumental variable regression.}, booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems}, articleno = {228}, numpages = {12}, location = {Vancouver, BC, Canada}, series = {NIPS'20} }

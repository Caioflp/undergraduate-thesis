\section{Proof of convergence}

To lighten the notation, the symbols $ \norm{ \cdot } $ and $ \dotprod{ \cdot, \cdot } $, when written without a subscript to specify which space they refer to, will act as the norm and inner product, respectively, of $ L^2 ( X ) $.

\begin{lemma}
    \label{lem: bound u_m}
    In the procedure of Algorithm \ref{algo: functional sgd} we have $ u_{ m } \in L^{ 2 } ( X ) $ for all $ 1 \leq m \leq M $ and, furthermore,
    \begin{equation*}
        \mean_{ \bz_{ 1:M } } [ \norm{ u_{ m } }^2 ] \leq
        \rho \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right) 
    ,\end{equation*}
    where
    \begin{equation*}
        \rho \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right) =
        3 \norm{ \hat{ \Phi } }_{ \infty }^2 \left(
            C_{ 0 }^2 + L^2 \norm{ \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + L^2 D^2 \norm{ \hat{ \meanop } }_{ \op }^2
        \right)
    .\end{equation*}
\end{lemma}
\begin{proof}
    By Assumption \ref{estimator assumptions} we have:
    \begin{align}
        \norm{ u_{ m } }_{ L^{ 2 } ( X ) }^2
        &= \norm{
            \hat{ \Phi } ( \cdot, \bz_{ m } ) \partial_{ 2 } \ell \left(
                \hat{ r_{ 0 } } ( \bz_{ m } ), \hat{ \meanop } [ \hat{ h }_{ m-1 } ] ( \bz_{ m } )
            \right)
        }_{ L^{ 2 } ( X ) }^2 \nonumber \\
        &= \mean_{ X } \left[
            \abs{ 
                \hat{ \Phi } ( X, \bz_{ m } ) \partial_{ 2 } \ell \left(
                    \hat{ r_{ 0 } } ( \bz_{ m } ),
                    \hat{ \meanop } [ \hat{ h }_{ m-1 } ] ( \bz_{ m } )
                \right)
            }^2
        \right] \nonumber \\
        &\leq \partial_{ 2 } \ell \left(
            \hat{ r_{ 0 } } ( \bz_{ m } ),
            \hat{ \meanop } [ \hat{ h }_{ m-1 } ] ( \bz_{ m } )
        \right)^2
        \norm{ \hat{ \Phi } }_{ \infty }^2 \\
        &< \infty \nonumber
    .\end{align}
    Hence, $ u_{ m } \in L^{ 2 } ( X ) $ for all $ m $.
    This computation and Proposition \ref{prop: loss properties}.\ref{bounded growth} then imply
    \begin{align*}
        \mean_{ \bz_{ 1:M } } \left[
            \norm{ u_{ m } }^2
        \right]
        &\leq 3 \norm{ \hat{ \Phi } }^2_{ \infty } 
        \left(
            C_{ 0 }^2 + L^2 \left(
                \norm{ \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2
                + \norm{ \hat{ \meanop } [ \hat{ h }_{ m-1 } ] }_{ L^2 ( Z ) }^2
            \right)
        \right) \\
        &\leq 3 \norm{ \hat{ \Phi } }^2_{ \infty }
        \left(
            C_{ 0 }^2 + L^2 \left(
                \norm{ \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2
                + \norm{ \hat{ \meanop } }_{ \op }^2 \norm{ \hat{ h }_{ m-1 } }^2
            \right)
        \right) \\
        &\leq 3 \norm{ \hat{ \Phi } }^2_{ \infty }
        \left(
            C_{ 0 }^2 + L^2 \left(
                \norm{ \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2
                + D^2 \norm{ \hat{ \meanop } }_{ \op }^2
            \right)
        \right) \\
        &= 3 \norm{ \hat{ \Phi } }^2_{ \infty }
        \left(
            C_{ 0 }^2 + L^2 \norm{ \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2
                + L^2 D^2 \norm{ \hat{ \meanop } }_{ \op }^2
        \right) \defeq \rho \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right) \qedhere.
    \end{align*}
\end{proof}
\begin{lemma}
    \label{lem: bound u_m - grad}
    In the procedure of Algorithm \ref{algo: functional sgd} we have\improvement{Comment on how this is the step that is different from the other article, since in the simpler scenario, this difference would vanish.}
    \begin{equation*}
        \norm{
            \mean_{ \bz_{ m } } \left[
                \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }
            \right]
        }
        \leq
        \kappa \left( \hat{ \Phi } \right) \left(
            \norm{ \Phi - \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 + \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + \norm{ \meanop - \hat{ \meanop } }_{ \op }^2
        \right)^{ \frac{ 1 }{ 2 } }
    ,\end{equation*}
    where
    \begin{equation*}
        \kappa^2 \left( \hat{ \Phi } \right) \defeq 2 \max \left\{
            3 ( C_{ 0 }^2 + L^2 \mean [ Y^2 ] + L^2 D^2 ),
            2L^2 \norm{ \hat{ \Phi } }_{ \infty }^2,
            2L^2 D^2 \norm{ \hat{ \Phi } }_{ \infty }^2
        \right\}
    .\end{equation*}
\end{lemma}
\begin{proof}
    To ease the notation, we define
    \begin{align*}
        \Psi_{ m } ( Z ) &\defeq \partial_{ 2 } \ell ( r_{ 0 } ( Z ), \meanop [ \hat{ h }_{ m-1 } ] ( Z ) ), \\
        \hat{ \Psi }_{ m } ( Z ) &\defeq \partial_{ 2 } \ell ( \hat{ r_{ 0 } } ( Z ), \hat{ \meanop } [ \hat{ h }_{ m-1 } ] ( Z ) )
    .\end{align*}
    Let's expand the definition of $ \norm{ \cdot } $:
    \begin{align*}
        \norm{
            \mean_{ \bz_{ m } } \left[
                \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }
            \right]
        }
        &= \mean_{ X } \left[
            \mean_{ \bz_{ m } } \left[
                \nabla \risk ( \hat{ h }_{ m-1 } ) ( X ) - u_{ m } ( X )
            \right]^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &= \mean_{ X } \left[
            \left(
                \nabla \risk ( \hat{ h }_{ m-1 } ) ( X ) - \mean_{ \bz_{ m } } \left[ u_{ m } ( X ) \right]
            \right)^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &= \mean_{ X } \left[
            \left(
                \mean_{ Z } \left[
                    \Phi ( X, Z ) \Psi_{ m } ( Z )
                \right]
                - \mean_{ \bz_{ m } } \left[
                    \hat{ \Phi } ( X, \bz_{ m } ) \hat{ \Psi }_{ m } ( \bz_{ m } )
                \right]
            \right)^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &= \mean_{ X } \left[
            \left(
                \mean_{ Z } \left[
                    \Phi ( X, Z ) \Psi_{ m } ( Z )
                    - \hat{ \Phi } ( X, Z ) \hat{ \Psi }_{ m } ( Z )
                \right]
            \right)^2
        \right]^{ \frac{ 1 }{ 2 } }
    ,\end{align*}
    Now we add and subtract $ \hat{ \Phi } ( X, Z ) \Psi_{ m } ( Z ) $, so that
    \begin{align*}
        &\mean_{ X } \left[
            \left(
                \mean_{ Z } \left[
                    \Phi ( X, Z ) \Psi_{ m } ( Z )
                    - \hat{ \Phi } ( X, Z ) \hat{ \Psi }_{ m } ( Z )
                \right]
            \right)^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &\hspace{1cm}
        = \mean_{ X } \left[
            \left(
                \mean_{ Z } \left[
                    \Psi_{ m } ( Z ) \left(
                        \Phi ( X, Z ) - \hat{ \Phi } ( X, Z )
                    \right)
                    + \hat{ \Phi } ( X, Z ) \left(
                        \Psi_{ m } ( Z ) - \hat{ \Psi }_{ m } ( Z )
                    \right)
                \right]
            \right)^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &\hspace{1cm}
        \leq \mean_{ X } \left[
            \left(
                \norm{ \Psi_{ m } }_{ L^{ 2 } ( Z ) } \norm{ \Phi ( X, \cdot ) - \hat{ \Phi } ( X, \cdot ) }_{ L^{ 2 } ( Z ) }
                + \norm{ \hat{ \Phi } ( X, \cdot ) }_{ L^{ 2 } ( Z ) } \norm{ \Psi_{ m } - \hat{ \Psi }_{ m } }_{ L^{ 2 } ( Z ) }
            \right)^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &\hspace{1cm}
        \leq \sqrt{ 2 } \mean_{ X } \left[
            \norm{ \Psi_{ m } }_{ L^{ 2 } ( Z ) }^2 \norm{ \Phi ( X, \cdot ) - \hat{ \Phi } ( X, \cdot ) }_{ L^{ 2 } ( Z ) }^2
            + \norm{ \hat{ \Phi } ( X, \cdot ) }_{ L^{ 2 } ( Z ) }^2 \norm{ \Psi_{ m } - \hat{ \Psi }_{ m } }_{ L^{ 2 } ( Z ) }^2
        \right]^{ \frac{ 1 }{ 2 } } \\
        &\hspace{1cm}
        = \sqrt{ 2 } \left(
            \norm{ \Psi_{ m } }_{ L^{ 2 } ( Z ) }^2 \norm{ \Phi - \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2
            + \norm{ \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 \norm{ \Psi_{ m } - \hat{ \Psi }_{ m } }_{ L^{ 2 } ( Z ) }^2
        \right)^{ \frac{ 1 }{ 2 } }
    ,\end{align*}
    where
    \begin{equation*}
        \norm{ \Phi }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 = \int_{ \mathcal{X} \times \mathcal{Z} } \Phi ( x, z )^2 p ( x ) p ( z ) \drm x \ddrm z
    \end{equation*}
    is the norm with respect to the independent coupling of the distributions of $ X $ and $ Z $.
    By Proposition \ref{prop: loss properties}.\ref{bounded growth} we have
    \begin{align*}
        \norm{ \Psi_{ m } }_{ L^{ 2 } ( Z ) }^2
        &= \mean_{ Z } \left[
            \partial_{ 2 } \ell ( r_{ 0 } ( Z ), \meanop [ \hat{ h }_{ m-1 } ] ( Z ) )^2
        \right] \\
        &\leq \mean_{ Z } \left[
            \left(
                C_{ 0 } + L \left(
                    \abs{ r_{ 0 } ( Z ) } + \abs{ \meanop [ \hat{ h }_{ m-1 } ] ( Z ) }
                \right)
            \right)^2
        \right] \\
        &\leq 3 \left(
            C_{ 0 }^2 + L^2 \norm{ r_{ 0 } }_{ L^{ 2 } ( Z ) }^2 + L^2 \norm{ \meanop [ \hat{ h }_{ m-1 } ] }_{ L^{ 2 } ( Z ) }^2
        \right) \\
        &\leq 3 \left(
            C_{ 0 }^2 + L^2 \mean [ Y^2 ] + L^2 D^2
        \right)
    .\end{align*}
    It is also clear that, by Assumption \ref{estimator assumptions},
    \begin{equation*}
        \norm{ \hat{ \Phi } }_{ L^2 ( \nu_{ X } \otimes \nu_{ Z } ) }^2 \leq \norm{ \hat{ \Phi } }_{ \infty }^2
    .\end{equation*}
    Finally, by Assumption \ref{assumption loss}.\ref{en: lipschitz gradients} we also have
    \begin{align*}
        \norm{ \Psi_{ m } - \hat{ \Psi }_{ m } }_{ L^{ 2 } ( Z ) }^2
        &= \mean_{ Z } \left[
            \left(
                \partial_{ 2 } \ell ( r_{ 0 } ( Z ), \meanop [ \hat{ h }_{ m-1 } ] ( Z ) )
                - \partial_{ 2 } \ell ( \hat{ r_{ 0 } } ( Z ), \hat{ \meanop } [ \hat{ h }_{ m-1 } ] ( Z ) )
            \right)^2
        \right] \\
        &\leq 2L^2 \left(
            \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^{ 2 } ( Z ) }^2 + \norm{ ( \meanop - \hat{ \meanop } ) [ \hat{ h }_{ m-1 } ] }_{ L^{ 2 } ( Z ) }^2
        \right) \\
        &\leq 2L^2 \left(
            \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^{ 2 } ( Z ) }^2 + D^2 \norm{ \meanop - \hat{ \meanop } }_{ \op }^2
        \right)
    .\end{align*}
    To combine all terms, we first define
    \begin{equation*}
        \kappa^2 \left( \hat{ \Phi } \right) \defeq 2 \max \left\{
            3 ( C_{ 0 }^2 + L^2 \mean [ Y^2 ] + L^2 D^2 ),
            2L^2 \norm{ \hat{ \Phi } }_{ \infty }^2,
            2L^2 D^2 \norm{ \hat{ \Phi } }_{ \infty }^2
        \right\}
    .\end{equation*}
    Then, it's easy to see that
    \begin{align*}
        \norm{
            \mean_{ \bz_{ m } } \left[
                \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }
            \right]
        } \leq \kappa \left( \hat{ \Phi } \right) \left(
            \norm{ \Phi - \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 + \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + \norm{ \meanop - \hat{ \meanop } }_{ \op }^2
        \right)^{ \frac{ 1 }{ 2 } }
    ,\end{align*}
    as we wanted to show.
\end{proof}
\begin{theorem}
    Assume that $ \hat{ h }_{ 0 }, \dots, \hat{ h }_{ M-1 } $ are generated according to Algorithm \ref{algo: functional sgd}.
    If we let $ \hat{ h } = \sum_{ m=1 }^{ M } \hat{ h }_{ m-1 } $, the following excess risk bound holds:
    \begin{align*}
        \begin{split}
            \mean_{ \bz_{ 1:M } } \left[
                \risk ( \hat{ h } ) - \risk ( \hstar )
            \right]
            &\leq \frac{ D^2 }{ 2 M \alpha_{ m } }
            + \xi \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right) \frac{ 1 }{ M } \sum_{ m=1 }^{ M } \alpha_{ m } \\
            &\hspace{1cm}
            + \tau \left( \hat{ \Phi } \right) \left(
                \norm{ \Phi - \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 + \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + \norm{ \meanop - \hat{ \meanop } }_{ \op }^2
            \right)^{ \frac{ 1 }{ 2 } },
        \end{split}
    \end{align*}
    where
    \begin{align*}
        \xi \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right)
        &= \frac{ 3 }{ 2 } \norm{ \hat{ \Phi } }_{ \infty }^2 \left(
            C_{ 0 }^2 + L^2 \norm{ \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + L^2 D ^2 \norm{ \hat{ \meanop } }_{ \op }^2
        \right), \\
        \tau \left( \hat{ \Phi } \right)
        &= 2 D \max \left\{
            3 ( C_{ 0 }^2 + L^2 \mean [ Y^2 ] + L^2 D^2 ),
            2L^2 \norm{ \hat{ \Phi } }_{ \infty }^2,
            2L^2 D^2 \norm{ \hat{ \Phi } }_{ \infty }^2
        \right\}
    .\end{align*}
\end{theorem}
\begin{proof}
    We start by checking that $ \risk $ is convex in $ \mathcal{F} $:
    if $ h, g \in \mathcal{F} $ and $ \lambda \in [ 0, 1 ] $, then
    \begin{align*}
        \risk ( \lambda h + ( 1 - \lambda ) g )
        &= \mean [ \loss ( r_{ 0 } ( Z ), \meanop [ \lambda h + ( 1 - \lambda ) g ] ( Z ) ) ] \\
        &= \mean [ \loss ( r_{ 0 } ( Z ), \lambda \meanop [ h ] ( Z ) + ( 1 - \lambda ) \meanop [ g ] ( Z ) ) ] \\
        &\leq \lambda \mean [ \loss ( r_{ 0 } ( Z ), \meanop [ h ] ( Z ) ) ] + ( 1 - \lambda ) \mean [ \loss ( r_{ 0 } ( Z ), \meanop [ g ] ( Z ) ) ] \\
        &= \lambda \risk ( h ) + ( 1 - \lambda ) \risk ( g )
    .\end{align*}
    By the Algorithm \ref{algo: functional sgd} procedure, we have
    \begin{align*}
        \frac{ 1 }{ 2 } \norm{ \hat{ h }_{ m } - \hstar }^2
        &= \frac{ 1 }{ 2 } \norm{ \pi_{ \mathcal{F} } \left[ \hat{ h }_{ m-1 } - \alpha_{ m } u_{ m } \right] - \hstar }^2 \\
        &\leq \frac{ 1 }{ 2 } \norm{ \hat{ h }_{ m-1 } - \alpha_{ m } u_{ m } - \hstar }^2 \\
        &= \frac{ 1 }{ 2 } \norm{ \hat{ h }_{ m-1 } - \hstar }^2
        - \alpha_{ m } \dotprod{ u_{ m }, \hat{ h }_{ m-1 } - \hstar }
        + \frac{ \alpha_{ m }^2 }{ 2 } \norm{ u_{ m } }^2
    .\end{align*}
    After adding and subtracting $ \alpha_{ m } \dotprod{ \nabla \risk ( \hat{ h }_{ m-1 } ), \hat{ h }_{ m-1 } - \hstar } $, we are left with
    \begin{equation*}
        \frac{ 1 }{ 2 } \norm{ \hat{ h }_{ m-1 } - \hstar }^2
        - \alpha_{ m } \dotprod{ u_{ m } - \nabla \risk ( \hat{ h }_{ m-1 } ), \hat{ h }_{ m-1 } - \hstar }
        + \frac{ \alpha_{ m }^2 }{ 2 } \norm{ u_{ m } }^2
        - \alpha_{ m } \dotprod{ \nabla \risk ( \hat{ h }_{ m-1 } ), \hat{ h }_{ m-1 } - \hstar }
    .\end{equation*}
    Applying the basic convexity inequality on the last term give us, in total,
    \begin{align*}
        \frac{ 1 }{ 2 } \norm{ \hat{ h }_{ m } - \hstar }^2
        &\leq
        \frac{ 1 }{ 2 } \norm{ \hat{ h }_{ m-1 } - \hstar }^2
        - \alpha_{ m } \dotprod{ u_{ m } - \nabla \risk ( \hat{ h }_{ m-1 } ), \hat{ h }_{ m-1 } - \hstar } \\
        &\hspace{1.5cm}
        + \frac{ \alpha_{ m }^2 }{ 2 } \norm{ u_{ m } }^2
        - \alpha_{ m } ( \risk ( \hat{ h }_{ m-1 } ) - \risk ( \hstar ) )
    .\end{align*}
    Rearranging terms, we get
    \begin{align*}
        \risk ( \hat{ h }_{ m-1 } ) - \risk ( \hstar )
        &\leq
        \frac{ 1 }{ 2 \alpha_{ m } } \left(
            \norm{ \hat{ h }_{ m-1 } - \hstar }^2
            -
            \norm{ \hat{ h }_{ m } - \hstar }^2
        \right) \\
        &\hspace{1.5cm}+ \frac{ \alpha_{ m } }{ 2 } \norm{ u_{ m } }^2
        - \dotprod{ u_{ m } - \nabla \risk ( \hat{ h }_{ m-1 } ), \hat{ h }_{ m-1 } - \hstar }
    .\end{align*}
    Finally, summing over $ 1 \leq m \leq M $ leads to
    \begin{align}
        \label{three sums}
        \begin{split}
            \sum_{ n=1 }^{ M } \left[
                \risk ( \hat{ h }_{ m-1 } ) - \risk ( \hstar )
            \right]
            &\leq \sum_{ m=1 }^{ M } \frac{ 1 }{ 2 \alpha_{ m } } \left(
                \norm{ \hat{ h }_{ m-1 } - \hstar }^2
                -
                \norm{ \hat{ h }_{ m } - \hstar }^2
            \right) \\
            &\hspace{1cm} + \sum_{ m=1 }^{ M } \frac{ \alpha_{ m } }{ 2 } \norm{ u_{ m } }^2 \\
            &\hspace{1cm} + \sum_{ m=1 }^{ M }
            \dotprod{ \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }, \hat{ h }_{ m-1 } - \hstar }.
        \end{split}
    \end{align}
    The next step is to take the average of both sides with respect to $ \bz_{ 1:M } $, taking advantage of the independence between $ \bz_{ 1:M } $ and $ \data_{ r_{ 0 }, \Phi, \meanop } $.
    Each summation in the RHS is then bounded separately.

    The first summation admits a deterministic bound:
    By assumption, we have $ \diam \mathcal{F} = D < \infty $.
    Hence
    \begin{align}
        \begin{split}
            \sum_{ m=1 }^{ M } \frac{ 1 }{ 2 \alpha_{ m } } \left(
                \norm{ \hat{ h }_{ m-1 } - \hstar }^2
                -
                \norm{ \hat{ h }_{ m } - \hstar }^2
            \right)
            &= \sum_{ m=2 }^{ M } \left(
                \frac{ 1 }{ 2 \alpha_{ m } } - \frac{ 1 }{ 2 \alpha_{ m-1 } } 
            \right) \norm{ \hat{ h }_{ m-1 } - \hstar }^2 \\
            &\hspace{1.5cm}+ \frac{ 1 }{ 2 \alpha_{ 1 } } \norm{ \hat{ h }_{ 0 } - \hstar }^2 - \frac{ 1 }{ 2 \alpha_{ M } } \norm{ \hat{ h }_{ M } - \hstar }^2
        \end{split} \nonumber \\
        &\leq 
        \sum_{ m=2 }^{ M } \left(
            \frac{ 1 }{ 2 \alpha_{ m } } - \frac{ 1 }{ 2 \alpha_{ m-1 } } 
        \right) D^2 + \frac{ 1 }{ 2 \alpha_{ 1 } } D^2 \nonumber \\
        &= \frac{ D^2 }{ 2 \alpha_{ M } } \label{bound first sum}
    .\end{align}
    The second summation can be bounded with the aid of Lemma \ref{lem: bound u_m}:
    \begin{equation}
        \mean_{ \bz_{ 1:M } } \left[
            \sum_{ m=1 }^{ M } \frac{ \alpha_{ m } }{ 2 } \norm{ u_{ m } }^2
        \right]
        = \frac{ \mean_{ \bz_{ 1:M } } \left[ \norm{ u_{ m } }^2 \right] }{ 2 } \sum_{ m=1 }^{ M } \alpha_{ m }
        \leq \frac{ \rho \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right) }{ 2 } 
        \sum_{ m=1 }^{ M } \alpha_{ m }
        \label{bound second sum}
    .\end{equation}
    Finally, the third summation can be bounded using Lemma \ref{lem: bound u_m - grad}.
    Let $ \mean_{ \bz_{ -m } } $ denote the expectation with respect to $ \bz_{ 1 }, \dots, \bz_{ m-1 }, \bz_{ m+1 }, \dots, \bz_{ M } $ and notice that
    \begin{align*}
        \mean_{ \bz_{ 1:M } } \left[
            \dotprod{ \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }, \hat{ h }_{ m-1 } - \hstar }
        \right]
        &= \mean_{ \bz_{ -m } } \left[
            \mean_{ \bz_{ m } } \left[
                \dotprod{ \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }, \hat{ h }_{ m-1 } - \hstar }
            \right]
        \right] \\
        &= \mean_{ \bz_{ -m } } \left[
                \dotprod{
                    \mean_{ \bz_{ m } } \left[
                        \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }
                    \right],
                    \hat{ h }_{ m-1 } - \hstar
                }
            \right] \\
        &= \mean_{ \bz_{ -m } } \left[
                \norm{
                    \mean_{ \bz_{ m } } \left[
                        \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }
                    \right]
                }
                \norm{
                    \hat{ h }_{ m-1 } - \hstar
                }
            \right] \\
        &\leq D \mean_{ \bz_{ -m } } \left[
                \norm{
                    \mean_{ \bz_{ m } } \left[
                        \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }
                    \right]
                }
            \right]
    .\end{align*}
    Then, applying Lemma \ref{lem: bound u_m - grad} and setting $ \tau \defeq D \kappa $ we get
    \begin{align}
        \begin{split}
            &\mean_{ \bz_{ 1:M } } \left[
                \dotprod{ \nabla \risk ( \hat{ h }_{ m-1 } ) - u_{ m }, \hat{ h }_{ m-1 } - \hstar }
            \right] \\
            &\hspace{2cm}
            \leq \tau \left( \hat{ \Phi } \right) \left(
                \norm{ \Phi - \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 + \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + \norm{ \meanop - \hat{ \meanop } }_{ \op }^2
            \right)^{ \frac{ 1 }{ 2 } }.
        \end{split}
        \label{bound third sum}
    \end{align}
    All that is left to do is to apply equations (\ref{three sums}), (\ref{bound first sum}), (\ref{bound second sum}) and (\ref{bound third sum}) along with a basic convexity inequality.
    Let $ \hat{ h } \defeq \frac{ 1 }{ M } \sum_{ m=1 }^{ M } \hat{ h }_{ m-1 } $ and $ \xi \defeq \rho / 2 $.
    Then:
    \begin{align*}
        &\mean_{ \bz_{ 1:M } } \left[
            \risk ( \hat{ h } ) - \risk ( \hstar )
        \right] \\
        &\hspace{1cm}
        \leq \frac{ 1 }{ M } \sum_{ m=1 }^{ M } \mean_{ \bz_{ 1:M } } \left[
            \risk ( \hat{ h }_{ m } ) - \risk ( \hstar )
        \right] \\
        &\hspace{1cm}
        \leq
        \frac{ D^2 }{ 2 M \alpha_{ m } }
        + \xi \left( \hat{ \Phi }, \hat{ r_{ 0 } }, \hat{ \meanop } \right) \frac{ 1 }{ M } \sum_{ m=1 }^{ M } \alpha_{ m } \\
        &\hspace{2.5cm}
        + \tau \left( \hat{ \Phi } \right) \left(
            \norm{ \Phi - \hat{ \Phi } }_{ L^{ 2 } ( \nu_{ X } \otimes \nu_{ Z } ) }^2 + \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^2 ( Z ) }^2 + \norm{ \meanop - \hat{ \meanop } }_{ \op }^2
        \right)^{ \frac{ 1 }{ 2 } }
    .\qedhere\end{align*} 
\end{proof}

{\color{red}
    What's left to do:
    \begin{itemize}
        % \item Bound $ \norm{ \hat{ \Phi } }_{ \mathcal{R}_{ \mathbb{W} } } $. (May not be strictly necessary. This is finite, and since it multiplies something which is $ \bigO_{ p } $ of something which goes to zero, we may not need to further bound it.) 

        \item Use some estimate on $ \norm{ \meanop - \hat{ \meanop } }_{ \mathrm{op} } $ (Adapt notation and setup in the KIV paper).

            {\color{blue}
                Conclusion (20/08/2023): We might need the extra hypothesis that $ \operatorname{Im} ( \operatorname{id}_{ L^2 ( X ) } - \iota_{ X } \iota_{ X }^{ * } ) \subseteq \ker \meanop $, where $ \iota_{ X } : \mathcal{H}_{ X } \to L^{ 2 } ( X ) $ is the inclusion operator, whose adjoint is given by
                \begin{equation*}
                    \iota_{ X }^{ * } ( f ) = ( x \mapsto \mean_{ X } [ f ( X ) k_{ X } ( X, x ) ] )
                ,\end{equation*}
                with $ k_{ X } : \mathbb{X} \times \mathbb{X} \to \R $ being the kernel associated with $ \mathcal{H}_{ X } $.
                Then $ \meanop = \meanop \circ \iota_{ X } \iota_{ X }^{ * } $ and we can directly apply the result on KIV's paper, since $ \meanop \circ i_{ X } $ can be seen as the restriction of $ \meanop $ to $ \mathcal{H}_{ X } $.
                We then also need the further hypothesis that $ \operatorname{Im} ( \meanop \circ \iota_{ X } ) \subseteq \mathcal{H}_{ Z } $, or something like this (because, rigorously speaking, $ \meanop f $ is an equivalence class of functions, so in what way can we say that this equivalence class is ``in $ \mathcal{H}_{ Z } $''?).
                This hypothesis is implicitly made in the KIV paper, when they say that $ E : \mathcal{H_{ X }} \to \mathcal{H}_{ Z } $ without providing any assumptions on $ \mathcal{H}_{ X } $ and $ \mathcal{H}_{ Z } $, other than saying that they are RKHS.
                Who can guarantee that $ (z \mapsto \mean [ f ( X ) \mid Z = z ]) \in \mathcal{H}_{ Z } $ for every $ f \in \mathcal{H}_{ X } $?
            }

        \item Find way to estimate $ r_{ 0 } $ which gives estimate on $ \norm{ r_{ 0 } - \hat{ r_{ 0 } } }_{ L^{ 2 } ( Z ) } $.
            Maybe use the same estimation technique we have for $ \meanop $ as an operator from $ L^2 ( Y ) \to L^2 ( Z ) $ applied to the identity and employ the same bound?
    \end{itemize}
    For the rest of the paper:
    \begin{itemize}
        \item Create section which describes, in detail, how we are estimating $ \Phi $, $ \meanop $ and $ r_{ 0 } $, lists all the references, states the main convergence theorems and lists all of the assumptions that are being made.

        \item Adapt the algorithm section to use the KIV first stage, which directly estimates $ \meanop $.

        \item Find better letter for either the number of iterations or the upper bound for the set $ \mathcal{F} $.
            Right now, both are being denoted by the letter $ M $.
    \end{itemize}
}

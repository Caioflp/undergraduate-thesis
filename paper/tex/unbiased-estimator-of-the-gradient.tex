\section{Unbiased estimator of the gradient}

We have found that
\begin{equation*}
    \nabla \risk ( h ) ( x )
    = \mathcal{T}^{ * } [ \partial_{ 2 } \ell ( r_{ 0 } ( \cdot ), \mathcal{T} [ h ] ( \cdot ) ) ] ( x )
    = \mean [ \partial_{ 2 } \ell ( r_{ 0 } ( Z ), \mathcal{T} [ h ] ( Z ) ) \mid X = x ]
.\end{equation*}
This turns out to be hard to estimate in practice, as we have two nested conditional expectation operators.
Our objective in this section is to find a random element\unsure{Should we discuss this further?} $ u_{ h } \in L^{ 2 } ( X ) $ such that $ \mean [ u_{ h } ( x ) ] = \nabla \risk ( h ) ( x ) $, so we can replace $ \nabla \risk ( h ) ( x ) $ by $ u_{ h } ( x ) $ in a gradient descent algorithm, obtaining a stochastic version which will be easier to compute.

Our strategy to obtain $ u_{ h } $ will be to write $ \nabla \risk ( h ) ( x ) = \mean [ \Phi ( x, Z ) \partial_{ 2 } \ell ( r_{ 0 } ( Z ), \mathcal{T} [ h ] ( Z ) ) ] $, for some suitable kernel $ \Phi $.
To ease the notation, define $ \xi_{ h } ( z ) \defeq \partial_{ 2 } \ell ( r_{ 0 } ( z ), \mathcal{T} [ h ] ( z ) ) $.
Assuming that $ X $ and $ Z $ have a joint distribution which is absolutely continuous with respect to Lebesgue measure in $ \R^{ p + q } $, we can write
\begin{align*}
    \nabla \risk ( h ) ( x )
    &= \mean [ \xi_{ h } ( Z ) \mid X = x ] \\
    &= \int_{ \mathbb{Z} } p ( z \mid x ) \xi_{ h } ( z ) \drm z \\
    &= \int_{ \mathbb{Z} } p ( z ) \frac{ p ( z \mid x ) }{ p ( z ) } \xi_{ h } ( z ) \drm z \\
    &= \mean \left[
        \frac{ p ( Z \mid x ) }{ p ( Z ) } \xi_{ h } ( Z )
    \right]
.\end{align*}
Thus, we must take
\begin{equation*}
    \Phi ( x, z )
    = \frac{ p ( z \mid x ) }{ p ( z ) }
    = \frac{ p ( x \mid z ) }{ p ( x ) }
    = \frac{ p ( x, z ) }{ p ( x ) p ( z ) }
.\end{equation*}
With this choice, setting $ u_{ h } ( x ) = \Phi ( x, Z ) \xi_{ h } ( Z ) $\improvement{Must discuss why $ u_{ h } \in L^{ 2 } ( X ) $.} we clearly have $ \mean [ u_{ h } ( x ) ] = \nabla \risk ( h ) ( x ) $.
